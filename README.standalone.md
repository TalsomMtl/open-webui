# Open WebUI Standalone - D√©ploiement Sans Ollama

Ce guide explique comment d√©ployer Open WebUI en mode standalone, **sans Ollama**, pour utiliser uniquement des APIs externes (OpenAI, Azure OpenAI, Anthropic, etc.).

## üìã Pr√©requis

- Docker Desktop install√© et d√©marr√©
- Git Bash ou terminal Linux/Mac
- Au moins 4 GB de RAM disponible
- 5 GB d'espace disque
- **Cl√©s API** pour les services LLM externes (OpenAI, Azure, etc.)

## üéØ Diff√©rence avec le d√©ploiement standard

| Fonctionnalit√© | Standard | Standalone |
|----------------|----------|------------|
| Ollama inclus | ‚úÖ Oui | ‚ùå Non |
| Mod√®les locaux | ‚úÖ Oui (Llama, Mistral, etc.) | ‚ùå Non |
| APIs externes | ‚úÖ Optionnel | ‚úÖ Requis |
| GPU n√©cessaire | ‚ö†Ô∏è Recommand√© | ‚ùå Non |
| RAM requise | 16+ GB | 4 GB |
| Espace disque | 20+ GB | 5 GB |
| Temps de d√©marrage | 5-10 min | 1-2 min |

## üöÄ D√©ploiement rapide

### Utiliser le script tout-en-un

```bash
cd /c/dev/workspace/open_webui-sync_fork/open-webui
./deploy-standalone.sh
```

**Ce script va:**
1. V√©rifier Docker
2. Arr√™ter les conteneurs existants
3. Builder l'image (sans Ollama, sans CUDA)
4. D√©marrer le conteneur
5. V√©rifier la sant√© du service

**Temps estim√©:** 10-15 minutes (premier build)

## ‚öôÔ∏è Configuration des APIs externes

### M√©thode 1: Fichier .env (RECOMMAND√â)

Cr√©ez ou modifiez le fichier `c:/dev/workspace/open_webui-sync_fork/.env`:

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_API_BASE_URL=https://api.openai.com/v1

# Azure OpenAI
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Autres variables
WEBUI_NAME=Mon Open WebUI
DO_NOT_TRACK=true
```

Ensuite, relancez le d√©ploiement:

```bash
./deploy-standalone.sh
```

### M√©thode 2: Configuration via l'interface web

1. Acc√©dez √† `http://localhost:8080`
2. Cr√©ez un compte administrateur
3. Allez dans **Settings** ‚Üí **Connections**
4. Configurez vos APIs:
   - **OpenAI API:** Ajoutez votre cl√© API
   - **Azure OpenAI:** Endpoint + cl√© + version
   - **Anthropic:** Cl√© API Claude

## üåê Acc√®s √† l'application

Une fois d√©ploy√©, Open WebUI est accessible sur:

**http://localhost:8080**

### Premier lancement

1. Cr√©ez un compte administrateur (premier utilisateur = admin)
2. Configurez vos connexions API dans Settings
3. Commencez √† utiliser les mod√®les externes

## üìÅ Structure des donn√©es

Les donn√©es sont stock√©es dans un volume Docker:

- **Volume:** `open-webui-data`
- **Contenu:** Base de donn√©es SQLite, uploads, param√®tres

### Voir les volumes

```bash
docker volume ls | grep open-webui
```

### Inspecter le volume

```bash
docker volume inspect open-webui-data
```

### Sauvegarder les donn√©es

```bash
# Cr√©er une sauvegarde
docker run --rm -v open-webui-data:/data -v $(pwd):/backup \
  alpine tar czf /backup/open-webui-backup.tar.gz -C /data .

# Restaurer une sauvegarde
docker run --rm -v open-webui-data:/data -v $(pwd):/backup \
  alpine tar xzf /backup/open-webui-backup.tar.gz -C /data
```

## üîß Commandes utiles

### Voir les logs en temps r√©el

```bash
docker logs -f open-webui-standalone
```

### Arr√™ter le conteneur

```bash
docker stop open-webui-standalone
```

### Red√©marrer le conteneur

```bash
docker restart open-webui-standalone
```

### Voir le statut

```bash
docker ps --filter "name=open-webui-standalone"
```

### Entrer dans le conteneur

```bash
docker exec -it open-webui-standalone bash
```

### Supprimer compl√®tement

```bash
# Arr√™ter et supprimer le conteneur
docker rm -f open-webui-standalone

# Supprimer l'image
docker rmi open-webui-standalone:latest

# Supprimer les donn√©es (‚ö†Ô∏è ATTENTION: perte d√©finitive)
docker volume rm open-webui-data
```

### Rebuild complet

```bash
# Supprimer le conteneur existant
docker rm -f open-webui-standalone

# Supprimer l'ancienne image
docker rmi open-webui-standalone:latest

# Rebuild et red√©ployer
./deploy-standalone.sh
```

## üêõ D√©pannage

### Le conteneur red√©marre en boucle

V√©rifiez les logs:

```bash
docker logs open-webui-standalone --tail=100
```

Causes communes:
- Cl√© API invalide (v√©rifiez dans les logs)
- M√©moire insuffisante (augmentez √† 4GB minimum)
- Port 8080 d√©j√† utilis√©

### Port 8080 d√©j√† utilis√©

Modifiez le port dans `deploy-standalone.sh`:

```bash
PORT="3000"  # Changez 8080 en 3000 (ou autre)
```

Puis relancez le script. Acc√®s via `http://localhost:3000`

### Erreur "Cannot connect to APIs"

1. V√©rifiez vos cl√©s API dans le fichier `.env`
2. V√©rifiez les logs pour voir les erreurs d'authentification:
   ```bash
   docker logs open-webui-standalone | grep -i "error\|api"
   ```
3. Testez vos cl√©s API manuellement:
   ```bash
   curl https://api.openai.com/v1/models \
     -H "Authorization: Bearer $OPENAI_API_KEY"
   ```

### Erreur de m√©moire lors du build

Augmentez la m√©moire allou√©e √† Docker Desktop:
- Ouvrir Docker Desktop
- Settings > Resources > Memory
- Augmenter √† au moins 4 GB

### Le service ne r√©pond pas

Attendez 1-2 minutes apr√®s le d√©marrage, puis v√©rifiez:

```bash
# V√©rifier si le processus tourne
docker exec open-webui-standalone ps aux | grep python

# V√©rifier les connexions r√©seau
curl -I http://localhost:8080
```

## üì¶ Partager l'image avec un coll√®gue

### Option 1: Exporter en fichier TAR

```bash
# Exporter l'image
docker save open-webui-standalone:latest | gzip > open-webui-standalone.tar.gz

# Partager le fichier .tar.gz (environ 2-3 GB)

# Votre coll√®gue importe:
docker load < open-webui-standalone.tar.gz
docker run -d -p 8080:8080 -v open-webui-data:/app/backend/data \
  --name open-webui-standalone open-webui-standalone:latest
```

### Option 2: Pousser vers Docker Hub

```bash
# Login
docker login

# Tag l'image
docker tag open-webui-standalone:latest votre-username/open-webui-standalone:latest

# Push
docker push votre-username/open-webui-standalone:latest

# Votre coll√®gue pull et run:
docker pull votre-username/open-webui-standalone:latest
docker run -d -p 8080:8080 -v open-webui-data:/app/backend/data \
  --name open-webui-standalone votre-username/open-webui-standalone:latest
```

### Option 3: Partager le code source

Partagez simplement ce r√©pertoire avec votre coll√®gue.
Il pourra d√©ployer avec `./deploy-standalone.sh`

## üìä Ressources syst√®me

### Utilisation typique:
- **CPU:** 5-15% (au repos)
- **RAM:** 1-2 GB (sans mod√®les locaux)
- **Disque:** 3-5 GB (image + donn√©es)

### Voir l'utilisation:

```bash
docker stats open-webui-standalone
```

## üîí S√©curit√©

### G√©n√©rer une cl√© secr√®te forte

```bash
# G√©n√©rer une cl√© al√©atoire
openssl rand -base64 32

# Ajouter dans .env
echo "WEBUI_SECRET_KEY=$(openssl rand -base64 32)" >> ../.env
```

### Activer HTTPS (production)

Pour un d√©ploiement en production, utilisez un reverse proxy (Nginx, Traefik, Caddy) avec SSL.

Exemple avec Caddy:

```caddyfile
your-domain.com {
    reverse_proxy localhost:8080
}
```

## üåê APIs support√©es

Open WebUI supporte les APIs suivantes en mode standalone:

### OpenAI
- GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
- Configuration: `OPENAI_API_KEY` + `OPENAI_API_BASE_URL`

### Azure OpenAI
- Tous les mod√®les d√©ploy√©s sur Azure
- Configuration: `AZURE_OPENAI_API_KEY` + `AZURE_OPENAI_ENDPOINT`

### Anthropic
- Claude 3 (Opus, Sonnet, Haiku)
- Configuration: `ANTHROPIC_API_KEY`

### Autres compatibles OpenAI
- Together AI
- Anyscale
- Groq
- Mistral AI
- Perplexity
- Tout service compatible avec l'API OpenAI

## üîó Liens utiles

- [Documentation Open WebUI](https://docs.openwebui.com/)
- [GitHub Open WebUI](https://github.com/open-webui/open-webui)
- [Documentation OpenAI API](https://platform.openai.com/docs)
- [Documentation Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/)
- [Documentation Anthropic API](https://docs.anthropic.com/)

## ‚úÖ Checklist de d√©ploiement

- [ ] Docker Desktop install√© et d√©marr√©
- [ ] Cl√©s API obtenues (OpenAI, Azure, ou autre)
- [ ] Fichier `.env` configur√© avec les cl√©s API
- [ ] Port 8080 disponible
- [ ] Au moins 4 GB RAM disponible
- [ ] Ex√©cuter `./deploy-standalone.sh`
- [ ] V√©rifier http://localhost:8080
- [ ] Cr√©er un compte administrateur
- [ ] Configurer les connexions API dans Settings
- [ ] Tester avec un premier message

## üìù Notes importantes

- **Base de donn√©es:** SQLite (locale, pas de configuration n√©cessaire)
- **Ollama:** **NON inclus** - utilisez uniquement des APIs externes
- **Pipelines:** NON inclus (pour ajouter Pipelines, voir docker-compose-combined.yml)
- **CUDA/GPU:** D√©sactiv√© (pas n√©cessaire sans mod√®les locaux)
- **Mod√®les locaux:** NON support√©s dans cette configuration

## üÜò Support

Si vous rencontrez des probl√®mes:

1. V√©rifiez les logs: `docker logs open-webui-standalone`
2. V√©rifiez votre configuration `.env`
3. Consultez la [documentation officielle](https://docs.openwebui.com/)
4. Ouvrez une issue sur [GitHub](https://github.com/open-webui/open-webui/issues)

## üîÑ Mise √† jour

Pour mettre √† jour vers la derni√®re version:

```bash
# Arr√™ter le conteneur actuel
docker stop open-webui-standalone
docker rm open-webui-standalone

# Supprimer l'ancienne image
docker rmi open-webui-standalone:latest

# Rebuild avec la derni√®re version
cd /c/dev/workspace/open_webui-sync_fork/open-webui
git pull  # Si vous utilisez Git
./deploy-standalone.sh
```

**Note:** Vos donn√©es dans le volume `open-webui-data` sont pr√©serv√©es!
